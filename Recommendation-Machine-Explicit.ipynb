{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Recomendation Machine with Explicit Feedback Data Example\n",
    "\n",
    "This example shows how to perform training and inference with SageMaker's built-in Recomendation Machine algorithm. We will build a Movie Recommendation System using the MovieLens dataset ([F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4: 19:1–19:19.](https://dl.acm.org/doi/10.1145/2827872) .\n",
    "\n",
    "The method we will use is a Factorization Machine classifier. Factorization Machine is a general-purpose supervised learning algorithm that you can use for classification and regression tasks. It is an extension of a linear model that is designed to parsimoniously capture interactions between features in high-dimensional sparse data sets. For example, in a click prediction system, the Factorization Machine model can capture observed click rate patterns. Factoring machines are a good choice for tasks related to high-dimensional sparse data sets, such as click prediction and item recommendation.\n",
    "\n",
    "The Amazon SageMaker Factorization Machine algorithm provides a robust and highly scalable implementation of this algorithm, which has become extremely popular in ad click prediction and recommendation systems.\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Prequisites and Preprocessing](#Prequisites-and-Preprocessing)\n",
    "    * [Import Library](#Library)\n",
    "    * [Permissions and environment variables](#Permissions-and-environment-variables)\n",
    "    * [Data inspection](#Data-inspection)\n",
    "    * [Exploratory data analysis](#Exploratory-data-analysis)\n",
    "    * [Preprocessing of the data](#Preprocessing-data)\n",
    "    * [Upload training data](#Upload-training-data)\n",
    "2. [Training the model](#Training-model)\n",
    "    * [Training parameters](#Training-parameters)\n",
    "    * [Launch the Training job](#Training-job)\n",
    "3. [Perform Batch Inference](#Batch-Inference)\n",
    "4. [Perform Real-Time Inference](#Real-Time-Inference)\n",
    "    * [Inferences](#Inferences)\n",
    "    * [Recommend function](#Recommend)\n",
    "5. [Cleanup](#Clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "The method that we’ll use is a factorization machine classifier. A factorization machine is a general-purpose supervised learning algorithm that you can use for both classification and regression tasks. It is an extension of a linear model that is designed to parsimoniously capture interactions between features in high dimensional sparse datasets.\n",
    "\n",
    "Amazon SageMaker’s Factorization Machine algorithm provides a robust, highly scalable implementation of this algorithm, which has become extremely popular in ad click prediction and recommender systems.\n",
    "\n",
    "FM is formulated as a linear model, with interactions between features as additional parameters (features). These feature interactions are done in their latent space representation instead of their plain format. It is represented mathematically as such:\n",
    "\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1200/0*vn90rfHHb5yPaZmo\" width=\"60%\" align=\"center\" />\n",
    "\n",
    "As mentioned, we can decompose the above equation into two parts — a Linear Regression model on the left-hand side and an equivalent matrix factorization on the right-hand side.\n",
    "\n",
    "To understand it more easily, let’s take a look at how we can represent the user-item matrix we saw in MF.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1200/1*LIUoxYjroygCiS5UhrMk4w.png\" width=\"60%\" align=\"center\" />\n",
    "\n",
    "For a start, we want to represent the user-item interaction as a one-hot encoding vector, where each row of the transformed will only have a single active user and item. We can then add in auxiliary features (e.g. other movies the user has rated, last movie rated, time he consumed that movie, etc) either as one-hot encodings or normalized vectors.\n",
    "\n",
    "Broadly speaking, factorization machines are able to estimate interactions in sparse settings because they break the independence of the interaction parameters by factorizing them (using latent vectors as expressed in <v_i, v_j>). This means that data for one interaction helps also to estimate the parameters for related interactions (similar to the idea of matrix factorization and collaborative filtering).\n",
    "\n",
    "To get started, we need to set up the environment with a few prerequisite steps, for permissions, configurations, and so on.!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Prequisites-and-Preprocessing'></a>\n",
    "\n",
    "## Prequisites and Preprocessing\n",
    "---\n",
    "This notebook was tested in Amazon SageMaker Studio on a ml.t3.medium instance with Python 3 (Data Science) kernel.\n",
    "\n",
    "<a id='Library'></a>\n",
    "### Import Library\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerias básicas\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from decimal import *\n",
    "import pprint\n",
    "\n",
    "# visualización\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10,7)})\n",
    "\n",
    "#matrices sparse\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "# Librerias para Amazon sagemaker\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "import io\n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter\n",
    "\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import JSONSerializer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Permissions-and-environment-variables'></a>\n",
    "\n",
    "### Permissions and environment variables\n",
    "\n",
    "Let’s start by specifying:\n",
    "\n",
    "   + The S3 buckets and prefixes that you want to use for training and model data and where the original data is located.\n",
    "\n",
    "   + The IAM role arn used to give training and hosting access to your data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role: arn:aws:iam::338408246139:role/service-role/AmazonSageMaker-ExecutionRole-20210707T172488 bucket: sagemaker-us-east-1-338408246139\n"
     ]
    }
   ],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"builtin-notebooks/Recomendation-Machine/Explicit\"\n",
    "print(f\"role: {role} bucket: {bucket}\")\n",
    "\n",
    "train_key = 'train.protobuf'\n",
    "train_prefix = '{}/{}'.format(prefix, 'train')\n",
    "s3_train = 's3://{}/{}/train/'.format(bucket,prefix)\n",
    "\n",
    "test_key = 'test.protobuf'\n",
    "test_prefix = '{}/{}'.format(prefix, 'test')\n",
    "\n",
    "#ubicación S3 de salida\n",
    "output_prefix = 's3://{}/{}/output'.format(bucket, prefix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Data-inspection'></a>\n",
    "\n",
    "### Data inspection\n",
    "\n",
    "Once the dataset is imported, it’s typical as part of the machine learning process to inspect the data, understand the distributions, and determine what type(s) of preprocessing might be needed.\n",
    "\n",
    "We start by downloading the data set. If this is the first time you have run this notebook, uncomment and run the following two lines of code, otherwise it is not necessary to run them again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "# !unzip -o ml-100k.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the downloaded .zip folder there are many different files. The datasets ua.base and ua.test split the u data into a training set and a test set with exactly 10 ratings per user in the test set. For more information consult the following [link](https://files.grouplens.org/datasets/movielens/ml-100k-README.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/Factorization-Machine/Algoritmo-MF-Edrans/Explicit/ml-100k\n",
      "1\t1\t5\t874965758\n",
      "1\t2\t3\t876893171\n",
      "1\t3\t4\t878542960\n",
      "1\t4\t3\t876893119\n",
      "1\t5\t3\t889751712\n",
      "1\t6\t5\t887431973\n",
      "1\t7\t4\t875071561\n",
      "1\t8\t1\t875072484\n",
      "1\t9\t5\t878543541\n",
      "1\t10\t3\t875693118\n"
     ]
    }
   ],
   "source": [
    "%cd ml-100k\n",
    "!head -10 ua.base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90570 ua.base\n"
     ]
    }
   ],
   "source": [
    "!wc -l ua.base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t20\t4\t887431883\n",
      "1\t33\t4\t878542699\n",
      "1\t61\t4\t878542420\n",
      "1\t117\t3\t874965739\n",
      "1\t155\t2\t878542201\n",
      "1\t160\t4\t875072547\n",
      "1\t171\t5\t889751711\n",
      "1\t189\t3\t888732928\n",
      "1\t202\t5\t875072442\n",
      "1\t265\t4\t878542441\n"
     ]
    }
   ],
   "source": [
    "!head -10 ua.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9430 ua.test\n"
     ]
    }
   ],
   "source": [
    "!wc -l ua.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dataset is already separated into train and test, we are going to read each of the databases in pandas dataframe format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of ratings dataset for training: (90570, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>874965758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1       5  874965758\n",
       "1       1        2       3  876893171\n",
       "2       1        3       4  878542960\n",
       "3       1        4       3  876893119\n",
       "4       1        5       3  889751712"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('ua.base', sep='\\t', names=['userId','movieId','rating','timestamp'] )\n",
    "ratings_test = pd.read_csv('ua.test', sep='\\t', names=['userId','movieId','rating','timestamp'] )\n",
    "\n",
    "#ratings.drop(columns='timestamp', inplace=True)\n",
    "print('Shape of ratings dataset for training: {}'.format(ratings.shape))\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET TRAIN:\n",
      "Number of raiting: 90570\n",
      "Number of different users: 943\n",
      "Number of different movies: 1680\n",
      "The dataset will consist of just over 90570 ratings applied to over 943 movies by approximately 1680 users. \n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET TRAIN:\")\n",
    "print(\"Number of raiting: {}\".format(ratings.shape[0]))\n",
    "print('Number of different users: {}'.format(len(ratings.userId.unique())))\n",
    "print('Number of different movies: {}'.format(len(ratings.movieId.unique())))\n",
    "print('The dataset will consist of just over {} ratings applied to over {} movies by approximately {} users. '.format(ratings.shape[0],len(ratings.userId.unique()),len(ratings.movieId.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET TEST:\n",
      "Number of raiting: 9430\n",
      "Number of different users: 943\n",
      "Number of different movies: 1129\n",
      "The dataset test will consist of just over 9430 ratings applied to over 943 movies by approximately 1129 users. \n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET TEST:\")\n",
    "print(\"Number of raiting: {}\".format(ratings_test.shape[0]))\n",
    "print('Number of different users: {}'.format(len(ratings_test.userId.unique())))\n",
    "print('Number of different movies: {}'.format(len(ratings_test.movieId.unique())))\n",
    "print('The dataset test will consist of just over {} ratings applied to over {} movies by approximately {} users. '.format(ratings_test.shape[0],len(ratings_test.userId.unique()),len(ratings_test.movieId.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Exploratory-data-analysis'></a>\n",
    "\n",
    "### Exploratory data analysis\n",
    "\n",
    "Once the dataset is imported, it’s typical as part of the machine learning process to inspect the data, understand the distributions, and determine what type(s) of preprocessing might be needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    90570.000000\n",
       "mean         3.523827\n",
       "std          1.126073\n",
       "min          1.000000\n",
       "25%          3.000000\n",
       "50%          4.000000\n",
       "75%          4.000000\n",
       "max          5.000000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.rating.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seaborn histogram\n",
    "sns.distplot(ratings['rating'], \n",
    "             hist=True, \n",
    "             kde=False, \n",
    "             color='blue',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "\n",
    "plt.title(\"Ratings Distribution\")\n",
    "plt.ylabel(\"Frecuency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are going to apply the mashine factorization algorithm for classification, we must convert the target variable (rating) into a binary variable. We will code as 1 those users who rated the film as good (rating greater than or equal to 4) and as 0 those who did not like it (rating less than 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>874965758</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp  rating_bin\n",
       "0       1        1       5  874965758         1.0\n",
       "1       1        2       3  876893171         0.0\n",
       "2       1        3       4  878542960         1.0\n",
       "3       1        4       3  876893119         0.0\n",
       "4       1        5       3  889751712         0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['rating_bin'] = (ratings.rating>=4).astype('float32')\n",
    "ratings_test['rating_bin'] = (ratings_test.rating>=4).astype('float32')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.55\n",
       "0.0    0.45\n",
       "Name: rating_bin, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(ratings.rating_bin.value_counts(normalize=True), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the dataset is quite balanced. Let's verify that all users have sufficient ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId\n",
       "202     10\n",
       "441     10\n",
       "685     10\n",
       "34      10\n",
       "36      10\n",
       "      ... \n",
       "276    508\n",
       "450    530\n",
       "13     626\n",
       "655    675\n",
       "405    727\n",
       "Name: rating, Length: 943, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.groupby('userId').count().rating.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId\n",
       "1      10\n",
       "622    10\n",
       "623    10\n",
       "624    10\n",
       "625    10\n",
       "       ..\n",
       "320    10\n",
       "321    10\n",
       "322    10\n",
       "310    10\n",
       "943    10\n",
       "Name: rating, Length: 943, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_test.groupby('userId').count().rating.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All users have at least 10 movie ratings. Let's verify that all users and movies that are present in test are also present in train, otherwise we remove them from the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users of the test dataset are on the train dataset: True\n",
      "Movie of the test dataset are on the train dataset: False\n"
     ]
    }
   ],
   "source": [
    "print('Users of the test dataset are on the train dataset: {}'.format(ratings_test.userId.isin(ratings.userId).sum()==len(ratings_test.userId)))\n",
    "print('Movie of the test dataset are on the train dataset: {}'.format(ratings_test.movieId.isin(ratings.movieId).sum()==len(ratings_test.movieId)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movies that are in the test dataset and not in the train dataset are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4049</th>\n",
       "      <td>405</td>\n",
       "      <td>1582</td>\n",
       "      <td>1</td>\n",
       "      <td>885548670</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6749</th>\n",
       "      <td>675</td>\n",
       "      <td>1653</td>\n",
       "      <td>5</td>\n",
       "      <td>889489913</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId  movieId  rating  timestamp  rating_bin\n",
       "4049     405     1582       1  885548670         0.0\n",
       "6749     675     1653       5  889489913         1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The movies that are in the test dataset and not in the train dataset are:')\n",
    "ratings_test[ratings_test.movieId.isin(ratings.movieId)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove the observations\n",
    "ratings_test = ratings_test.drop(index=ratings_test[ratings_test.movieId.isin(ratings.movieId)==False].index)\n",
    "ratings_test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users of the test dataset are on the train dataset: True\n",
      "Movie of the test dataset are on the train dataset: True\n"
     ]
    }
   ],
   "source": [
    "print('Users of the test dataset are on the train dataset: {}'.format(ratings_test.userId.isin(ratings.userId).sum()==len(ratings_test.userId)))\n",
    "print('Movie of the test dataset are on the train dataset: {}'.format(ratings_test.movieId.isin(ratings.movieId).sum()==len(ratings_test.movieId)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Preprocessing-data'></a>\n",
    "\n",
    "### Preprocessing of the data\n",
    "\n",
    "One-hot Encoding is a type of vector representation in which all of the elements in a vector are 0, except for one, which has 1 as its value, where 1 represents a boolean specifying a category of the element.  A similar technique to this one, also used to represent data, would be dummy variables in statistics. [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n",
    "\n",
    "In our example we must transform with `OneHotEncoder` the variables **userId** and **movieId** to transform them into columns and represent them as binary variables. The `fit` y `transform` method is applied to the train dataset and the `transform` method is applied to the test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=True)\n",
    "enc.fit(ratings[['userId','movieId']])\n",
    "\n",
    "X_train_OH = enc.transform(ratings[['userId','movieId']]).astype('float32')\n",
    "Y_train_OH = ratings['rating_bin']\n",
    "\n",
    "X_test_OH = enc.transform(ratings_test[['userId','movieId']]).astype('float32')\n",
    "Y_test_OH = ratings_test['rating_bin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (0, 943)\t1.0\n",
      "  (0, 0)\t1.0\n",
      "  (0, 962)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train_OH[0,:])\n",
    "print(X_test_OH[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       0.0\n",
      "4       0.0\n",
      "       ... \n",
      "9423    1.0\n",
      "9424    1.0\n",
      "9425    0.0\n",
      "9426    1.0\n",
      "9427    0.0\n",
      "Name: rating_bin, Length: 9428, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "print(Y_test_OH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:2623 \n",
      "Rows:90570 \n"
     ]
    }
   ],
   "source": [
    "columns = X_train_OH.shape[1]\n",
    "\n",
    "print(\"Columns:{} \".format(X_train_OH.shape[1]))\n",
    "print(\"Rows:{} \".format(X_train_OH.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Upload-training-data'></a>\n",
    "\n",
    "### Upload training data\n",
    "\n",
    "Since algorithms have particular input and output requirements, converting the dataset is also part of the process that a data scientist goes through prior to initiating training. In this particular case, the Amazon SageMaker implementation of Factorization Machines takes recordIO-wrapped protobuf, where the data we have today is a pickle-ized numpy array on disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que permite guardar en formato protobuf en un bucket de S3\n",
    "def writeDatasetToProtobuf(X, Y, bucket, prefix, key):\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_spmatrix_to_sparse_tensor(buf, X, Y)\n",
    "    buf.seek(0)\n",
    "    obj = '{}/{}'.format(prefix, key)\n",
    "    boto3.resource('s3').Bucket(bucket).Object(obj).upload_fileobj(buf)\n",
    "    return 's3://{}/{}'.format(bucket, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-338408246139/builtin-notebooks/Recomendation-Machine/Explicit/train/train.protobuf\n",
      "s3://sagemaker-us-east-1-338408246139/builtin-notebooks/Recomendation-Machine/Explicit/test/test.protobuf\n",
      "Output: s3://sagemaker-us-east-1-338408246139/builtin-notebooks/Recomendation-Machine/Explicit/output\n",
      "CPU times: user 12.6 s, sys: 229 ms, total: 12.8 s\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data = writeDatasetToProtobuf(X_train_OH, Y_train_OH, bucket, train_prefix, train_key)    \n",
    "test_data = writeDatasetToProtobuf(X_test_OH, Y_test_OH, bucket, test_prefix, test_key)    \n",
    "  \n",
    "print(train_data)\n",
    "print(test_data)\n",
    "print('Output: {}'.format(output_prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Training-model'></a>\n",
    "## Training the model\n",
    "---\n",
    "\n",
    "Now that we are done with all the setup that is needed, we are ready to train our Factorization Machine. To begin, let us create a ``sageMaker.estimator.Estimator`` object. This estimator will launch the training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Training-parameters'></a>\n",
    "### Training parameters\n",
    "There are two kinds of parameters that need to be set for training. The first one are the parameters for the training job. These include:\n",
    "\n",
    "* **image_uri**: Container image for the algorithm\n",
    "* **Training instance count**: This is the number of instances on which to run the training. When the number of instances is greater than one, then the Factorization Machine algorithm will run in distributed settings. \n",
    "* **Training instance type**: This indicates the type of machine on which to run the training. \n",
    "* **Volume size**: Size in GB of the EBS volume to use for storing input data during training. Must be large enough to store training data.\n",
    "* **Max run time**: Timeout in seconds for training. After this amount of time Amazon SageMaker terminates the job regardless of its current status.\n",
    "* **Output path**: This the s3 folder in which the training output is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "training_image = retrieve(region=boto3.Session().region_name, framework=\"factorization-machines\", version='latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = sagemaker.estimator.Estimator(\n",
    "    training_image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c4.xlarge',\n",
    "    volume_size=30,\n",
    "    max_run=86400,\n",
    "    output_path=output_prefix,\n",
    "    sagemaker_session=sess,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the above set of parameters, there are hyperparameters that are specific to the algorithm. These are:\n",
    "\n",
    "* **feature_dim**: The dimension of the input feature space. This could be very high with sparse input.\n",
    "* **num_factors**: The dimensionality of factorization. As mentioned initially, factorization machines find a lower dimensional representation of the interactions for all features. Making this value smaller provides a more parsimonious model, closer to a linear model, but may sacrifice information about interactions. Making it larger provides a higher-dimensional representation of feature interactions, but adds computational complexity and can lead to overfitting. In a practical application, time should be invested to tune this parameter to the appropriate value.\n",
    "* **predictor_type**: The type of predictor. binary_classifier: For binary classification tasks. regressor: For regression tasks.\n",
    "* **epochs**: The number of training epochs to run.\n",
    "* **mini_batch_size**: The size of mini-batch used for training. This value can be tuned for relatively minor improvements in fit and speed, but selecting a reasonable value relative to the dataset is appropriate in most cases.\n",
    "\n",
    "You can check all the available hyperparameters at [Factorization Machines Hyperparameters](https://docs.aws.amazon.com/sagemaker/latest/dg/fact-machines-hyperparameters.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.set_hyperparameters(\n",
    "    feature_dim=columns,\n",
    "    num_factors=64,\n",
    "    predictor_type='binary_classifier',\n",
    "    epochs=30,\n",
    "    mini_batch_size=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Input-data-specification'></a>\n",
    "### Input data specification\n",
    "\n",
    "Set the data type and channels used for training. We have to specify `train` and `test` channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_channels = {\n",
    "    \"train\": train_data,\n",
    "    \"test\": test_data\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Training-job'></a>\n",
    "### Launch the Training job\n",
    "\n",
    "Start training by calling the fit method in the estimator. This will launch a SageMaker Training job with the requested parameters and hyperparameters.\n",
    "\n",
    "When it's done, run the next cell to see the training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-22 19:00:47 Starting - Starting the training job...\n",
      "2021-12-22 19:00:52 Starting - Launching requested ML instancesProfilerReport-1640199647: InProgress\n",
      "......\n",
      "2021-12-22 19:02:16 Starting - Preparing the instances for training............\n",
      "2021-12-22 19:04:17 Downloading - Downloading input data...\n",
      "2021-12-22 19:04:46 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/jsonref.py:8: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, MutableMapping, Sequence\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/algorithm/network_builder.py:87: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/algorithm/network_builder.py:120: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:50 INFO 139703438038848] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-conf.json: {'epochs': 1, 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0'}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:50 INFO 139703438038848] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'feature_dim': '2623', 'predictor_type': 'binary_classifier', 'num_factors': '64', 'epochs': '30', 'mini_batch_size': '200'}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:50 INFO 139703438038848] Final configuration: {'epochs': '30', 'mini_batch_size': '200', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0', 'feature_dim': '2623', 'predictor_type': 'binary_classifier', 'num_factors': '64'}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:50 WARNING 139703438038848] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:50 INFO 139703438038848] Using default worker.\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:50 INFO 139703438038848] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:04:50.653] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:04:50.656] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 6, \"num_examples\": 1, \"num_bytes\": 12800}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:50 INFO 139703438038848] nvidia-smi: took 0.079 seconds to run.\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:50 INFO 139703438038848] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:50 INFO 139703438038848] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:50 INFO 139703438038848] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:50 INFO 139703438038848] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199890.6494658, \"EndTime\": 1640199890.7663908, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 111.38343811035156, \"count\": 1, \"min\": 111.38343811035156, \"max\": 111.38343811035156}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199890.7665415, \"EndTime\": 1640199890.7665846, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 200.0, \"count\": 1, \"min\": 200, \"max\": 200}, \"Total Batches Seen\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Max Records Seen Between Resets\": {\"sum\": 200.0, \"count\": 1, \"min\": 200, \"max\": 200}, \"Max Batches Seen Between Resets\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[19:04:50] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.205844.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[19:04:50] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.205844.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:50 INFO 139703438038848] #quality_metric: host=algo-1, epoch=0, batch=0 train binary_classification_accuracy <score>=0.62\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:50 INFO 139703438038848] #quality_metric: host=algo-1, epoch=0, batch=0 train binary_classification_cross_entropy <loss>=0.6894251251220703\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:50 INFO 139703438038848] #quality_metric: host=algo-1, epoch=0, batch=0 train binary_f_1.000 <score>=0.7654320987654321\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:04:52.422] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 1622, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:52 INFO 139703438038848] #quality_metric: host=algo-1, epoch=0, train binary_classification_accuracy <score>=0.5513907284768212\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:52 INFO 139703438038848] #quality_metric: host=algo-1, epoch=0, train binary_classification_cross_entropy <loss>=0.6858020927311306\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:52 INFO 139703438038848] #quality_metric: host=algo-1, epoch=0, train binary_f_1.000 <score>=0.6713511765181531\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199890.7664855, \"EndTime\": 1640199892.4237647, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 30.0, \"count\": 1, \"min\": 30, \"max\": 30}, \"update.time\": {\"sum\": 1656.874179840088, \"count\": 1, \"min\": 1656.874179840088, \"max\": 1656.874179840088}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:52 INFO 139703438038848] #progress_metric: host=algo-1, completed 3.3333333333333335 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199890.766857, \"EndTime\": 1640199892.4240441, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 90770.0, \"count\": 1, \"min\": 90770, \"max\": 90770}, \"Total Batches Seen\": {\"sum\": 454.0, \"count\": 1, \"min\": 454, \"max\": 454}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:52 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=54648.40497448539 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:52 INFO 139703438038848] #quality_metric: host=algo-1, epoch=1, batch=0 train binary_classification_accuracy <score>=0.62\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:52 INFO 139703438038848] #quality_metric: host=algo-1, epoch=1, batch=0 train binary_classification_cross_entropy <loss>=0.6507969665527343\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:52 INFO 139703438038848] #quality_metric: host=algo-1, epoch=1, batch=0 train binary_f_1.000 <score>=0.7654320987654321\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:04:53.924] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 1498, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:53 INFO 139703438038848] #quality_metric: host=algo-1, epoch=1, train binary_classification_accuracy <score>=0.5663576158940398\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:53 INFO 139703438038848] #quality_metric: host=algo-1, epoch=1, train binary_classification_cross_entropy <loss>=0.6731621593618499\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:53 INFO 139703438038848] #quality_metric: host=algo-1, epoch=1, train binary_f_1.000 <score>=0.6808344706570482\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199892.4238508, \"EndTime\": 1640199893.9254673, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1501.1036396026611, \"count\": 1, \"min\": 1501.1036396026611, \"max\": 1501.1036396026611}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:53 INFO 139703438038848] #progress_metric: host=algo-1, completed 6.666666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199892.4243298, \"EndTime\": 1640199893.9257352, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 181340.0, \"count\": 1, \"min\": 181340, \"max\": 181340}, \"Total Batches Seen\": {\"sum\": 907.0, \"count\": 1, \"min\": 907, \"max\": 907}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:53 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=60317.77872976364 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:53 INFO 139703438038848] #quality_metric: host=algo-1, epoch=2, batch=0 train binary_classification_accuracy <score>=0.62\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:53 INFO 139703438038848] #quality_metric: host=algo-1, epoch=2, batch=0 train binary_classification_cross_entropy <loss>=0.636888427734375\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:53 INFO 139703438038848] #quality_metric: host=algo-1, epoch=2, batch=0 train binary_f_1.000 <score>=0.7654320987654321\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:04:55.263] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 1335, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:55 INFO 139703438038848] #quality_metric: host=algo-1, epoch=2, train binary_classification_accuracy <score>=0.5864459161147902\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:55 INFO 139703438038848] #quality_metric: host=algo-1, epoch=2, train binary_classification_cross_entropy <loss>=0.6633392490614329\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:55 INFO 139703438038848] #quality_metric: host=algo-1, epoch=2, train binary_f_1.000 <score>=0.6907356048600105\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199893.9255495, \"EndTime\": 1640199895.26454, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1338.4788036346436, \"count\": 1, \"min\": 1338.4788036346436, \"max\": 1338.4788036346436}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:55 INFO 139703438038848] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199893.926029, \"EndTime\": 1640199895.2648487, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 271910.0, \"count\": 1, \"min\": 271910, \"max\": 271910}, \"Total Batches Seen\": {\"sum\": 1360.0, \"count\": 1, \"min\": 1360, \"max\": 1360}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:55 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=67642.42734742006 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:55 INFO 139703438038848] #quality_metric: host=algo-1, epoch=3, batch=0 train binary_classification_accuracy <score>=0.66\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:55 INFO 139703438038848] #quality_metric: host=algo-1, epoch=3, batch=0 train binary_classification_cross_entropy <loss>=0.6262996673583985\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:55 INFO 139703438038848] #quality_metric: host=algo-1, epoch=3, batch=0 train binary_f_1.000 <score>=0.7848101265822784\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:04:56.534] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 1267, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:56 INFO 139703438038848] #quality_metric: host=algo-1, epoch=3, train binary_classification_accuracy <score>=0.6065121412803532\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:56 INFO 139703438038848] #quality_metric: host=algo-1, epoch=3, train binary_classification_cross_entropy <loss>=0.6555191934345573\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:56 INFO 139703438038848] #quality_metric: host=algo-1, epoch=3, train binary_f_1.000 <score>=0.7003043193167107\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199895.264622, \"EndTime\": 1640199896.5354793, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1270.310878753662, \"count\": 1, \"min\": 1270.310878753662, \"max\": 1270.310878753662}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:56 INFO 139703438038848] #progress_metric: host=algo-1, completed 13.333333333333334 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199895.2651405, \"EndTime\": 1640199896.5356812, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 362480.0, \"count\": 1, \"min\": 362480, \"max\": 362480}, \"Total Batches Seen\": {\"sum\": 1813.0, \"count\": 1, \"min\": 1813, \"max\": 1813}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:56 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=71278.2037082938 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:56 INFO 139703438038848] #quality_metric: host=algo-1, epoch=4, batch=0 train binary_classification_accuracy <score>=0.665\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:56 INFO 139703438038848] #quality_metric: host=algo-1, epoch=4, batch=0 train binary_classification_cross_entropy <loss>=0.618043327331543\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:56 INFO 139703438038848] #quality_metric: host=algo-1, epoch=4, batch=0 train binary_f_1.000 <score>=0.7859424920127795\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:04:57.890] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 1352, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:57 INFO 139703438038848] #quality_metric: host=algo-1, epoch=4, train binary_classification_accuracy <score>=0.6243046357615895\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:57 INFO 139703438038848] #quality_metric: host=algo-1, epoch=4, train binary_classification_cross_entropy <loss>=0.6490889570728833\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:57 INFO 139703438038848] #quality_metric: host=algo-1, epoch=4, train binary_f_1.000 <score>=0.7086286594761171\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199896.5355434, \"EndTime\": 1640199897.8911893, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1355.0059795379639, \"count\": 1, \"min\": 1355.0059795379639, \"max\": 1355.0059795379639}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:57 INFO 139703438038848] #progress_metric: host=algo-1, completed 16.666666666666668 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199896.5360827, \"EndTime\": 1640199897.891571, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 453050.0, \"count\": 1, \"min\": 453050, \"max\": 453050}, \"Total Batches Seen\": {\"sum\": 2266.0, \"count\": 1, \"min\": 2266, \"max\": 2266}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:57 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=66806.53290521227 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:57 INFO 139703438038848] #quality_metric: host=algo-1, epoch=5, batch=0 train binary_classification_accuracy <score>=0.685\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:57 INFO 139703438038848] #quality_metric: host=algo-1, epoch=5, batch=0 train binary_classification_cross_entropy <loss>=0.6114289474487304\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:57 INFO 139703438038848] #quality_metric: host=algo-1, epoch=5, batch=0 train binary_f_1.000 <score>=0.7961165048543689\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:04:59.253] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 1350, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:59 INFO 139703438038848] #quality_metric: host=algo-1, epoch=5, train binary_classification_accuracy <score>=0.6383995584988963\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:59 INFO 139703438038848] #quality_metric: host=algo-1, epoch=5, train binary_classification_cross_entropy <loss>=0.6436392950432717\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:59 INFO 139703438038848] #quality_metric: host=algo-1, epoch=5, train binary_f_1.000 <score>=0.7156928257153023\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199897.8912845, \"EndTime\": 1640199899.2540352, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1361.9415760040283, \"count\": 1, \"min\": 1361.9415760040283, \"max\": 1361.9415760040283}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:59 INFO 139703438038848] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199897.8920622, \"EndTime\": 1640199899.2543116, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 543620.0, \"count\": 1, \"min\": 543620, \"max\": 543620}, \"Total Batches Seen\": {\"sum\": 2719.0, \"count\": 1, \"min\": 2719, \"max\": 2719}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:59 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=66478.72466894785 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:59 INFO 139703438038848] #quality_metric: host=algo-1, epoch=6, batch=0 train binary_classification_accuracy <score>=0.695\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:59 INFO 139703438038848] #quality_metric: host=algo-1, epoch=6, batch=0 train binary_classification_cross_entropy <loss>=0.6059894180297851\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:04:59 INFO 139703438038848] #quality_metric: host=algo-1, epoch=6, batch=0 train binary_f_1.000 <score>=0.7986798679867987\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:00.585] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 1329, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:00 INFO 139703438038848] #quality_metric: host=algo-1, epoch=6, train binary_classification_accuracy <score>=0.6489293598233996\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:00 INFO 139703438038848] #quality_metric: host=algo-1, epoch=6, train binary_classification_cross_entropy <loss>=0.638899607542598\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:00 INFO 139703438038848] #quality_metric: host=algo-1, epoch=6, train binary_f_1.000 <score>=0.7208908467080266\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199899.2541351, \"EndTime\": 1640199900.5863636, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1331.7310810089111, \"count\": 1, \"min\": 1331.7310810089111, \"max\": 1331.7310810089111}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:00 INFO 139703438038848] #progress_metric: host=algo-1, completed 23.333333333333332 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199899.2545986, \"EndTime\": 1640199900.586572, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 634190.0, \"count\": 1, \"min\": 634190, \"max\": 634190}, \"Total Batches Seen\": {\"sum\": 3172.0, \"count\": 1, \"min\": 3172, \"max\": 3172}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:00 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=67990.51716219616 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:00 INFO 139703438038848] #quality_metric: host=algo-1, epoch=7, batch=0 train binary_classification_accuracy <score>=0.71\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:00 INFO 139703438038848] #quality_metric: host=algo-1, epoch=7, batch=0 train binary_classification_cross_entropy <loss>=0.6014059829711914\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:00 INFO 139703438038848] #quality_metric: host=algo-1, epoch=7, batch=0 train binary_f_1.000 <score>=0.8066666666666666\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:01.929] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 1341, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:01 INFO 139703438038848] #quality_metric: host=algo-1, epoch=7, train binary_classification_accuracy <score>=0.6571743929359823\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:01 INFO 139703438038848] #quality_metric: host=algo-1, epoch=7, train binary_classification_cross_entropy <loss>=0.6346878567962984\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:01 INFO 139703438038848] #quality_metric: host=algo-1, epoch=7, train binary_f_1.000 <score>=0.7251230132040072\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199900.5864332, \"EndTime\": 1640199901.9304206, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1343.5845375061035, \"count\": 1, \"min\": 1343.5845375061035, \"max\": 1343.5845375061035}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:01 INFO 139703438038848] #progress_metric: host=algo-1, completed 26.666666666666668 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199900.5868132, \"EndTime\": 1640199901.9307456, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 724760.0, \"count\": 1, \"min\": 724760, \"max\": 724760}, \"Total Batches Seen\": {\"sum\": 3625.0, \"count\": 1, \"min\": 3625, \"max\": 3625}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:01 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=67385.62644748195 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:01 INFO 139703438038848] #quality_metric: host=algo-1, epoch=8, batch=0 train binary_classification_accuracy <score>=0.715\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:01 INFO 139703438038848] #quality_metric: host=algo-1, epoch=8, batch=0 train binary_classification_cross_entropy <loss>=0.5974574279785156\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:01 INFO 139703438038848] #quality_metric: host=algo-1, epoch=8, batch=0 train binary_f_1.000 <score>=0.8067796610169492\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:03.489] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 1556, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:03 INFO 139703438038848] #quality_metric: host=algo-1, epoch=8, train binary_classification_accuracy <score>=0.6643267108167771\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:03 INFO 139703438038848] #quality_metric: host=algo-1, epoch=8, train binary_classification_cross_entropy <loss>=0.6308788040194817\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:03 INFO 139703438038848] #quality_metric: host=algo-1, epoch=8, train binary_f_1.000 <score>=0.7289724623473843\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199901.930585, \"EndTime\": 1640199903.4898596, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1558.793544769287, \"count\": 1, \"min\": 1558.793544769287, \"max\": 1558.793544769287}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:03 INFO 139703438038848] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199901.9310331, \"EndTime\": 1640199903.4901268, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 815330.0, \"count\": 1, \"min\": 815330, \"max\": 815330}, \"Total Batches Seen\": {\"sum\": 4078.0, \"count\": 1, \"min\": 4078, \"max\": 4078}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:03 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=58086.510810309934 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:03 INFO 139703438038848] #quality_metric: host=algo-1, epoch=9, batch=0 train binary_classification_accuracy <score>=0.71\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:03 INFO 139703438038848] #quality_metric: host=algo-1, epoch=9, batch=0 train binary_classification_cross_entropy <loss>=0.5939879608154297\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:03 INFO 139703438038848] #quality_metric: host=algo-1, epoch=9, batch=0 train binary_f_1.000 <score>=0.8\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:05.063] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 1570, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:05 INFO 139703438038848] #quality_metric: host=algo-1, epoch=9, train binary_classification_accuracy <score>=0.6702980132450331\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:05 INFO 139703438038848] #quality_metric: host=algo-1, epoch=9, train binary_classification_cross_entropy <loss>=0.6273843320631823\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:05 INFO 139703438038848] #quality_metric: host=algo-1, epoch=9, train binary_f_1.000 <score>=0.732379476244658\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199903.4899435, \"EndTime\": 1640199905.0641823, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1573.7202167510986, \"count\": 1, \"min\": 1573.7202167510986, \"max\": 1573.7202167510986}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:05 INFO 139703438038848] #progress_metric: host=algo-1, completed 33.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199903.4904277, \"EndTime\": 1640199905.0644333, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 905900.0, \"count\": 1, \"min\": 905900, \"max\": 905900}, \"Total Batches Seen\": {\"sum\": 4531.0, \"count\": 1, \"min\": 4531, \"max\": 4531}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:05 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=57535.94056993094 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:05 INFO 139703438038848] #quality_metric: host=algo-1, epoch=10, batch=0 train binary_classification_accuracy <score>=0.73\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:05 INFO 139703438038848] #quality_metric: host=algo-1, epoch=10, batch=0 train binary_classification_cross_entropy <loss>=0.5908863067626953\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:05 INFO 139703438038848] #quality_metric: host=algo-1, epoch=10, batch=0 train binary_f_1.000 <score>=0.8111888111888111\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:06.593] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 1525, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:06 INFO 139703438038848] #quality_metric: host=algo-1, epoch=10, train binary_classification_accuracy <score>=0.6750993377483444\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:06 INFO 139703438038848] #quality_metric: host=algo-1, epoch=10, train binary_classification_cross_entropy <loss>=0.6241411480261527\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:06 INFO 139703438038848] #quality_metric: host=algo-1, epoch=10, train binary_f_1.000 <score>=0.7352068078369286\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199905.0642562, \"EndTime\": 1640199906.5944989, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1529.714822769165, \"count\": 1, \"min\": 1529.714822769165, \"max\": 1529.714822769165}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:06 INFO 139703438038848] #progress_metric: host=algo-1, completed 36.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199905.064756, \"EndTime\": 1640199906.5948117, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 996470.0, \"count\": 1, \"min\": 996470, \"max\": 996470}, \"Total Batches Seen\": {\"sum\": 4984.0, \"count\": 1, \"min\": 4984, \"max\": 4984}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:06 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=59188.313550043495 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:06 INFO 139703438038848] #quality_metric: host=algo-1, epoch=11, batch=0 train binary_classification_accuracy <score>=0.735\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:06 INFO 139703438038848] #quality_metric: host=algo-1, epoch=11, batch=0 train binary_classification_cross_entropy <loss>=0.588071517944336\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:06 INFO 139703438038848] #quality_metric: host=algo-1, epoch=11, batch=0 train binary_f_1.000 <score>=0.8140350877192982\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:07.932] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 1335, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:07 INFO 139703438038848] #quality_metric: host=algo-1, epoch=11, train binary_classification_accuracy <score>=0.6796467991169978\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:07 INFO 139703438038848] #quality_metric: host=algo-1, epoch=11, train binary_classification_cross_entropy <loss>=0.621102894241973\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:07 INFO 139703438038848] #quality_metric: host=algo-1, epoch=11, train binary_f_1.000 <score>=0.7378660067556583\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199906.5945997, \"EndTime\": 1640199907.9333072, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1338.1338119506836, \"count\": 1, \"min\": 1338.1338119506836, \"max\": 1338.1338119506836}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:07 INFO 139703438038848] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199906.5951452, \"EndTime\": 1640199907.9335198, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1087040.0, \"count\": 1, \"min\": 1087040, \"max\": 1087040}, \"Total Batches Seen\": {\"sum\": 5437.0, \"count\": 1, \"min\": 5437, \"max\": 5437}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 13.0, \"count\": 1, \"min\": 13, \"max\": 13}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:07 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=67665.75382639021 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:07 INFO 139703438038848] #quality_metric: host=algo-1, epoch=12, batch=0 train binary_classification_accuracy <score>=0.74\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:07 INFO 139703438038848] #quality_metric: host=algo-1, epoch=12, batch=0 train binary_classification_cross_entropy <loss>=0.5854842376708984\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:07 INFO 139703438038848] #quality_metric: host=algo-1, epoch=12, batch=0 train binary_f_1.000 <score>=0.8169014084507042\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:09.335] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 1399, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:09 INFO 139703438038848] #quality_metric: host=algo-1, epoch=12, train binary_classification_accuracy <score>=0.6836313465783664\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:09 INFO 139703438038848] #quality_metric: host=algo-1, epoch=12, train binary_classification_cross_entropy <loss>=0.618235033468958\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:09 INFO 139703438038848] #quality_metric: host=algo-1, epoch=12, train binary_f_1.000 <score>=0.7403408010001178\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199907.9333813, \"EndTime\": 1640199909.3357089, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1401.8917083740234, \"count\": 1, \"min\": 1401.8917083740234, \"max\": 1401.8917083740234}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:09 INFO 139703438038848] #progress_metric: host=algo-1, completed 43.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199907.933791, \"EndTime\": 1640199909.335966, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1177610.0, \"count\": 1, \"min\": 1177610, \"max\": 1177610}, \"Total Batches Seen\": {\"sum\": 5890.0, \"count\": 1, \"min\": 5890, \"max\": 5890}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 14.0, \"count\": 1, \"min\": 14, \"max\": 14}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:09 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=64586.04206206432 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:09 INFO 139703438038848] #quality_metric: host=algo-1, epoch=13, batch=0 train binary_classification_accuracy <score>=0.745\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:09 INFO 139703438038848] #quality_metric: host=algo-1, epoch=13, batch=0 train binary_classification_cross_entropy <loss>=0.5830802154541016\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:09 INFO 139703438038848] #quality_metric: host=algo-1, epoch=13, batch=0 train binary_f_1.000 <score>=0.8197879858657244\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:10.737] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 1399, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:10 INFO 139703438038848] #quality_metric: host=algo-1, epoch=13, train binary_classification_accuracy <score>=0.6876931567328919\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:10 INFO 139703438038848] #quality_metric: host=algo-1, epoch=13, train binary_classification_cross_entropy <loss>=0.6155113983154297\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:10 INFO 139703438038848] #quality_metric: host=algo-1, epoch=13, train binary_f_1.000 <score>=0.7429993551141266\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199909.3358157, \"EndTime\": 1640199910.7378373, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1401.6296863555908, \"count\": 1, \"min\": 1401.6296863555908, \"max\": 1401.6296863555908}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:10 INFO 139703438038848] #progress_metric: host=algo-1, completed 46.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199909.3361802, \"EndTime\": 1640199910.7380347, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1268180.0, \"count\": 1, \"min\": 1268180, \"max\": 1268180}, \"Total Batches Seen\": {\"sum\": 6343.0, \"count\": 1, \"min\": 6343, \"max\": 6343}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 15.0, \"count\": 1, \"min\": 15, \"max\": 15}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:10 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=64602.55038830087 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:10 INFO 139703438038848] #quality_metric: host=algo-1, epoch=14, batch=0 train binary_classification_accuracy <score>=0.74\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:10 INFO 139703438038848] #quality_metric: host=algo-1, epoch=14, batch=0 train binary_classification_cross_entropy <loss>=0.5808261871337891\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:10 INFO 139703438038848] #quality_metric: host=algo-1, epoch=14, batch=0 train binary_f_1.000 <score>=0.8156028368794326\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:11.993] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 1253, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:11 INFO 139703438038848] #quality_metric: host=algo-1, epoch=14, train binary_classification_accuracy <score>=0.6906953642384106\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:11 INFO 139703438038848] #quality_metric: host=algo-1, epoch=14, train binary_classification_cross_entropy <loss>=0.6129118707585283\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:11 INFO 139703438038848] #quality_metric: host=algo-1, epoch=14, train binary_f_1.000 <score>=0.7449741998307291\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199910.7379014, \"EndTime\": 1640199911.994427, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1256.150245666504, \"count\": 1, \"min\": 1256.150245666504, \"max\": 1256.150245666504}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:11 INFO 139703438038848] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199910.7382457, \"EndTime\": 1640199911.994778, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1358750.0, \"count\": 1, \"min\": 1358750, \"max\": 1358750}, \"Total Batches Seen\": {\"sum\": 6796.0, \"count\": 1, \"min\": 6796, \"max\": 6796}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:11 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=72070.85268582318 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:12 INFO 139703438038848] #quality_metric: host=algo-1, epoch=15, batch=0 train binary_classification_accuracy <score>=0.745\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:12 INFO 139703438038848] #quality_metric: host=algo-1, epoch=15, batch=0 train binary_classification_cross_entropy <loss>=0.5786966705322265\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:12 INFO 139703438038848] #quality_metric: host=algo-1, epoch=15, batch=0 train binary_f_1.000 <score>=0.8185053380782918\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:13.247] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 1250, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:13 INFO 139703438038848] #quality_metric: host=algo-1, epoch=15, train binary_classification_accuracy <score>=0.6935540838852097\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:13 INFO 139703438038848] #quality_metric: host=algo-1, epoch=15, train binary_classification_cross_entropy <loss>=0.6104207651504617\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:13 INFO 139703438038848] #quality_metric: host=algo-1, epoch=15, train binary_f_1.000 <score>=0.7468266705573388\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199911.9945755, \"EndTime\": 1640199913.2478628, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1252.5174617767334, \"count\": 1, \"min\": 1252.5174617767334, \"max\": 1252.5174617767334}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:13 INFO 139703438038848] #progress_metric: host=algo-1, completed 53.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199911.9953213, \"EndTime\": 1640199913.2480626, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1449320.0, \"count\": 1, \"min\": 1449320, \"max\": 1449320}, \"Total Batches Seen\": {\"sum\": 7249.0, \"count\": 1, \"min\": 7249, \"max\": 7249}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 17.0, \"count\": 1, \"min\": 17, \"max\": 17}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:13 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=72290.93903518862 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:13 INFO 139703438038848] #quality_metric: host=algo-1, epoch=16, batch=0 train binary_classification_accuracy <score>=0.74\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:13 INFO 139703438038848] #quality_metric: host=algo-1, epoch=16, batch=0 train binary_classification_cross_entropy <loss>=0.5766721343994141\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:13 INFO 139703438038848] #quality_metric: host=algo-1, epoch=16, batch=0 train binary_f_1.000 <score>=0.8142857142857143\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:14.577] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 34, \"duration\": 1326, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:14 INFO 139703438038848] #quality_metric: host=algo-1, epoch=16, train binary_classification_accuracy <score>=0.6961368653421633\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:14 INFO 139703438038848] #quality_metric: host=algo-1, epoch=16, train binary_classification_cross_entropy <loss>=0.6080256894513735\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:14 INFO 139703438038848] #quality_metric: host=algo-1, epoch=16, train binary_f_1.000 <score>=0.748593658679135\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199913.2479284, \"EndTime\": 1640199914.5776803, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1329.0939331054688, \"count\": 1, \"min\": 1329.0939331054688, \"max\": 1329.0939331054688}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:14 INFO 139703438038848] #progress_metric: host=algo-1, completed 56.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199913.24856, \"EndTime\": 1640199914.577882, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1539890.0, \"count\": 1, \"min\": 1539890, \"max\": 1539890}, \"Total Batches Seen\": {\"sum\": 7702.0, \"count\": 1, \"min\": 7702, \"max\": 7702}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 18.0, \"count\": 1, \"min\": 18, \"max\": 18}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:14 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=68126.99741697901 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:14 INFO 139703438038848] #quality_metric: host=algo-1, epoch=17, batch=0 train binary_classification_accuracy <score>=0.745\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:14 INFO 139703438038848] #quality_metric: host=algo-1, epoch=17, batch=0 train binary_classification_cross_entropy <loss>=0.5747373962402343\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:14 INFO 139703438038848] #quality_metric: host=algo-1, epoch=17, batch=0 train binary_f_1.000 <score>=0.8172043010752689\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:15.870] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 36, \"duration\": 1290, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:15 INFO 139703438038848] #quality_metric: host=algo-1, epoch=17, train binary_classification_accuracy <score>=0.6986092715231788\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:15 INFO 139703438038848] #quality_metric: host=algo-1, epoch=17, train binary_classification_cross_entropy <loss>=0.6057167327746124\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:15 INFO 139703438038848] #quality_metric: host=algo-1, epoch=17, train binary_f_1.000 <score>=0.7503200321860941\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199914.5777466, \"EndTime\": 1640199915.8707707, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1292.3002243041992, \"count\": 1, \"min\": 1292.3002243041992, \"max\": 1292.3002243041992}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:15 INFO 139703438038848] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199914.578438, \"EndTime\": 1640199915.8710413, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1630460.0, \"count\": 1, \"min\": 1630460, \"max\": 1630460}, \"Total Batches Seen\": {\"sum\": 8155.0, \"count\": 1, \"min\": 8155, \"max\": 8155}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 19.0, \"count\": 1, \"min\": 19, \"max\": 19}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:15 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=70060.49881375338 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:15 INFO 139703438038848] #quality_metric: host=algo-1, epoch=18, batch=0 train binary_classification_accuracy <score>=0.745\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:15 INFO 139703438038848] #quality_metric: host=algo-1, epoch=18, batch=0 train binary_classification_cross_entropy <loss>=0.5728804397583008\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:15 INFO 139703438038848] #quality_metric: host=algo-1, epoch=18, batch=0 train binary_f_1.000 <score>=0.8172043010752689\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:17.143] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 38, \"duration\": 1269, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:17 INFO 139703438038848] #quality_metric: host=algo-1, epoch=18, train binary_classification_accuracy <score>=0.7012472406181015\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:17 INFO 139703438038848] #quality_metric: host=algo-1, epoch=18, train binary_classification_cross_entropy <loss>=0.6034858648034911\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:17 INFO 139703438038848] #quality_metric: host=algo-1, epoch=18, train binary_f_1.000 <score>=0.7520587723396265\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199915.8708565, \"EndTime\": 1640199917.1436577, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1272.2878456115723, \"count\": 1, \"min\": 1272.2878456115723, \"max\": 1272.2878456115723}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:17 INFO 139703438038848] #progress_metric: host=algo-1, completed 63.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199915.8713424, \"EndTime\": 1640199917.1438737, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1721030.0, \"count\": 1, \"min\": 1721030, \"max\": 1721030}, \"Total Batches Seen\": {\"sum\": 8608.0, \"count\": 1, \"min\": 8608, \"max\": 8608}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:17 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=71166.34349527622 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:17 INFO 139703438038848] #quality_metric: host=algo-1, epoch=19, batch=0 train binary_classification_accuracy <score>=0.745\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:17 INFO 139703438038848] #quality_metric: host=algo-1, epoch=19, batch=0 train binary_classification_cross_entropy <loss>=0.5710917663574219\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:17 INFO 139703438038848] #quality_metric: host=algo-1, epoch=19, batch=0 train binary_f_1.000 <score>=0.8172043010752689\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:18.413] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 40, \"duration\": 1266, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:18 INFO 139703438038848] #quality_metric: host=algo-1, epoch=19, train binary_classification_accuracy <score>=0.7032671081677704\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:18 INFO 139703438038848] #quality_metric: host=algo-1, epoch=19, train binary_classification_cross_entropy <loss>=0.6013265069115241\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:18 INFO 139703438038848] #quality_metric: host=algo-1, epoch=19, train binary_f_1.000 <score>=0.7533351683640701\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199917.143721, \"EndTime\": 1640199918.4138086, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1269.340991973877, \"count\": 1, \"min\": 1269.340991973877, \"max\": 1269.340991973877}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:18 INFO 139703438038848] #progress_metric: host=algo-1, completed 66.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199917.1444361, \"EndTime\": 1640199918.4140797, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1811600.0, \"count\": 1, \"min\": 1811600, \"max\": 1811600}, \"Total Batches Seen\": {\"sum\": 9061.0, \"count\": 1, \"min\": 9061, \"max\": 9061}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 21.0, \"count\": 1, \"min\": 21, \"max\": 21}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:18 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=71327.30761171375 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:18 INFO 139703438038848] #quality_metric: host=algo-1, epoch=20, batch=0 train binary_classification_accuracy <score>=0.75\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:18 INFO 139703438038848] #quality_metric: host=algo-1, epoch=20, batch=0 train binary_classification_cross_entropy <loss>=0.5693638610839844\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:18 INFO 139703438038848] #quality_metric: host=algo-1, epoch=20, batch=0 train binary_f_1.000 <score>=0.8201438848920863\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:19.727] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 42, \"duration\": 1310, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:19 INFO 139703438038848] #quality_metric: host=algo-1, epoch=20, train binary_classification_accuracy <score>=0.7052869757174393\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:19 INFO 139703438038848] #quality_metric: host=algo-1, epoch=20, train binary_classification_cross_entropy <loss>=0.5992331991132521\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:19 INFO 139703438038848] #quality_metric: host=algo-1, epoch=20, train binary_f_1.000 <score>=0.7546427750976338\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199918.4138913, \"EndTime\": 1640199919.7275815, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1312.894582748413, \"count\": 1, \"min\": 1312.894582748413, \"max\": 1312.894582748413}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:19 INFO 139703438038848] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199918.414662, \"EndTime\": 1640199919.7277775, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1902170.0, \"count\": 1, \"min\": 1902170, \"max\": 1902170}, \"Total Batches Seen\": {\"sum\": 9514.0, \"count\": 1, \"min\": 9514, \"max\": 9514}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 22.0, \"count\": 1, \"min\": 22, \"max\": 22}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:19 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=68967.9167747662 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:19 INFO 139703438038848] #quality_metric: host=algo-1, epoch=21, batch=0 train binary_classification_accuracy <score>=0.755\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:19 INFO 139703438038848] #quality_metric: host=algo-1, epoch=21, batch=0 train binary_classification_cross_entropy <loss>=0.5676905822753906\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:19 INFO 139703438038848] #quality_metric: host=algo-1, epoch=21, batch=0 train binary_f_1.000 <score>=0.8231046931407943\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:21.018] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 44, \"duration\": 1288, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:21 INFO 139703438038848] #quality_metric: host=algo-1, epoch=21, train binary_classification_accuracy <score>=0.7074172185430464\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:21 INFO 139703438038848] #quality_metric: host=algo-1, epoch=21, train binary_classification_cross_entropy <loss>=0.597201360235151\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:21 INFO 139703438038848] #quality_metric: host=algo-1, epoch=21, train binary_f_1.000 <score>=0.756005964544099\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199919.7276456, \"EndTime\": 1640199921.0193474, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1290.9753322601318, \"count\": 1, \"min\": 1290.9753322601318, \"max\": 1290.9753322601318}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:21 INFO 139703438038848] #progress_metric: host=algo-1, completed 73.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199919.7283435, \"EndTime\": 1640199921.019659, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1992740.0, \"count\": 1, \"min\": 1992740, \"max\": 1992740}, \"Total Batches Seen\": {\"sum\": 9967.0, \"count\": 1, \"min\": 9967, \"max\": 9967}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:21 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=70130.86062668369 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:21 INFO 139703438038848] #quality_metric: host=algo-1, epoch=22, batch=0 train binary_classification_accuracy <score>=0.755\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:21 INFO 139703438038848] #quality_metric: host=algo-1, epoch=22, batch=0 train binary_classification_cross_entropy <loss>=0.5660668182373046\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:21 INFO 139703438038848] #quality_metric: host=algo-1, epoch=22, batch=0 train binary_f_1.000 <score>=0.8231046931407943\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:22.273] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 46, \"duration\": 1251, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:22 INFO 139703438038848] #quality_metric: host=algo-1, epoch=22, train binary_classification_accuracy <score>=0.709150110375276\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:22 INFO 139703438038848] #quality_metric: host=algo-1, epoch=22, train binary_classification_cross_entropy <loss>=0.5952270879177068\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:22 INFO 139703438038848] #quality_metric: host=algo-1, epoch=22, train binary_f_1.000 <score>=0.7571403555662055\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199921.0194323, \"EndTime\": 1640199922.274491, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1254.2269229888916, \"count\": 1, \"min\": 1254.2269229888916, \"max\": 1254.2269229888916}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:22 INFO 139703438038848] #progress_metric: host=algo-1, completed 76.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199921.0202394, \"EndTime\": 1640199922.2747674, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2083310.0, \"count\": 1, \"min\": 2083310, \"max\": 2083310}, \"Total Batches Seen\": {\"sum\": 10420.0, \"count\": 1, \"min\": 10420, \"max\": 10420}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 24.0, \"count\": 1, \"min\": 24, \"max\": 24}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:22 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=72186.57804884722 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:22 INFO 139703438038848] #quality_metric: host=algo-1, epoch=23, batch=0 train binary_classification_accuracy <score>=0.755\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:22 INFO 139703438038848] #quality_metric: host=algo-1, epoch=23, batch=0 train binary_classification_cross_entropy <loss>=0.564488525390625\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:22 INFO 139703438038848] #quality_metric: host=algo-1, epoch=23, batch=0 train binary_f_1.000 <score>=0.8231046931407943\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:23.549] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 48, \"duration\": 1272, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:23 INFO 139703438038848] #quality_metric: host=algo-1, epoch=23, train binary_classification_accuracy <score>=0.7111479028697572\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:23 INFO 139703438038848] #quality_metric: host=algo-1, epoch=23, train binary_classification_cross_entropy <loss>=0.5933070428271431\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:23 INFO 139703438038848] #quality_metric: host=algo-1, epoch=23, train binary_f_1.000 <score>=0.7584991325532464\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199922.2745798, \"EndTime\": 1640199923.5500805, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1274.71923828125, \"count\": 1, \"min\": 1274.71923828125, \"max\": 1274.71923828125}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:23 INFO 139703438038848] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199922.2753386, \"EndTime\": 1640199923.5502913, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2173880.0, \"count\": 1, \"min\": 2173880, \"max\": 2173880}, \"Total Batches Seen\": {\"sum\": 10873.0, \"count\": 1, \"min\": 10873, \"max\": 10873}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 25.0, \"count\": 1, \"min\": 25, \"max\": 25}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:23 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=71031.86189368878 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:23 INFO 139703438038848] #quality_metric: host=algo-1, epoch=24, batch=0 train binary_classification_accuracy <score>=0.76\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:23 INFO 139703438038848] #quality_metric: host=algo-1, epoch=24, batch=0 train binary_classification_cross_entropy <loss>=0.5629522323608398\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:23 INFO 139703438038848] #quality_metric: host=algo-1, epoch=24, batch=0 train binary_f_1.000 <score>=0.8260869565217391\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:24.879] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 50, \"duration\": 1326, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:24 INFO 139703438038848] #quality_metric: host=algo-1, epoch=24, train binary_classification_accuracy <score>=0.7127041942604857\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:24 INFO 139703438038848] #quality_metric: host=algo-1, epoch=24, train binary_classification_cross_entropy <loss>=0.5914383108884294\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:24 INFO 139703438038848] #quality_metric: host=algo-1, epoch=24, train binary_f_1.000 <score>=0.7595717756163346\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199923.5501447, \"EndTime\": 1640199924.8800058, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1329.071283340454, \"count\": 1, \"min\": 1329.071283340454, \"max\": 1329.071283340454}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:24 INFO 139703438038848] #progress_metric: host=algo-1, completed 83.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199923.5509071, \"EndTime\": 1640199924.8802173, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2264450.0, \"count\": 1, \"min\": 2264450, \"max\": 2264450}, \"Total Batches Seen\": {\"sum\": 11326.0, \"count\": 1, \"min\": 11326, \"max\": 11326}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 26.0, \"count\": 1, \"min\": 26, \"max\": 26}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:24 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=68127.82823983167 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:24 INFO 139703438038848] #quality_metric: host=algo-1, epoch=25, batch=0 train binary_classification_accuracy <score>=0.76\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:24 INFO 139703438038848] #quality_metric: host=algo-1, epoch=25, batch=0 train binary_classification_cross_entropy <loss>=0.561454963684082\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:24 INFO 139703438038848] #quality_metric: host=algo-1, epoch=25, batch=0 train binary_f_1.000 <score>=0.8260869565217391\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:26.156] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 52, \"duration\": 1274, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:26 INFO 139703438038848] #quality_metric: host=algo-1, epoch=25, train binary_classification_accuracy <score>=0.7142494481236203\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:26 INFO 139703438038848] #quality_metric: host=algo-1, epoch=25, train binary_classification_cross_entropy <loss>=0.5896183184861611\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:26 INFO 139703438038848] #quality_metric: host=algo-1, epoch=25, train binary_f_1.000 <score>=0.7606040150541413\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199924.880077, \"EndTime\": 1640199926.15722, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1276.3943672180176, \"count\": 1, \"min\": 1276.3943672180176, \"max\": 1276.3943672180176}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:26 INFO 139703438038848] #progress_metric: host=algo-1, completed 86.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199924.8807948, \"EndTime\": 1640199926.157423, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2355020.0, \"count\": 1, \"min\": 2355020, \"max\": 2355020}, \"Total Batches Seen\": {\"sum\": 11779.0, \"count\": 1, \"min\": 11779, \"max\": 11779}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 27.0, \"count\": 1, \"min\": 27, \"max\": 27}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:26 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=70938.51957214829 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:26 INFO 139703438038848] #quality_metric: host=algo-1, epoch=26, batch=0 train binary_classification_accuracy <score>=0.76\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:26 INFO 139703438038848] #quality_metric: host=algo-1, epoch=26, batch=0 train binary_classification_cross_entropy <loss>=0.5599942779541016\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:26 INFO 139703438038848] #quality_metric: host=algo-1, epoch=26, batch=0 train binary_f_1.000 <score>=0.8260869565217391\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:27.411] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 54, \"duration\": 1251, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:27 INFO 139703438038848] #quality_metric: host=algo-1, epoch=26, train binary_classification_accuracy <score>=0.7159050772626931\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:27 INFO 139703438038848] #quality_metric: host=algo-1, epoch=26, train binary_classification_cross_entropy <loss>=0.5878447936439093\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:27 INFO 139703438038848] #quality_metric: host=algo-1, epoch=26, train binary_f_1.000 <score>=0.7617222577091491\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199926.1572855, \"EndTime\": 1640199927.4119737, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1253.9608478546143, \"count\": 1, \"min\": 1253.9608478546143, \"max\": 1253.9608478546143}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:27 INFO 139703438038848] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199926.1579823, \"EndTime\": 1640199927.4122357, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2445590.0, \"count\": 1, \"min\": 2445590, \"max\": 2445590}, \"Total Batches Seen\": {\"sum\": 12232.0, \"count\": 1, \"min\": 12232, \"max\": 12232}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:27 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=72202.27405221215 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:27 INFO 139703438038848] #quality_metric: host=algo-1, epoch=27, batch=0 train binary_classification_accuracy <score>=0.76\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:27 INFO 139703438038848] #quality_metric: host=algo-1, epoch=27, batch=0 train binary_classification_cross_entropy <loss>=0.5585680389404297\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:27 INFO 139703438038848] #quality_metric: host=algo-1, epoch=27, batch=0 train binary_f_1.000 <score>=0.8260869565217391\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:28.683] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 56, \"duration\": 1269, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:28 INFO 139703438038848] #quality_metric: host=algo-1, epoch=27, train binary_classification_accuracy <score>=0.7172516556291391\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:28 INFO 139703438038848] #quality_metric: host=algo-1, epoch=27, train binary_classification_cross_entropy <loss>=0.5861156861092608\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:28 INFO 139703438038848] #quality_metric: host=algo-1, epoch=27, train binary_f_1.000 <score>=0.762548316231473\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199927.4120567, \"EndTime\": 1640199928.6844606, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1271.6012001037598, \"count\": 1, \"min\": 1271.6012001037598, \"max\": 1271.6012001037598}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:28 INFO 139703438038848] #progress_metric: host=algo-1, completed 93.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199927.4128284, \"EndTime\": 1640199928.6848898, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2536160.0, \"count\": 1, \"min\": 2536160, \"max\": 2536160}, \"Total Batches Seen\": {\"sum\": 12685.0, \"count\": 1, \"min\": 12685, \"max\": 12685}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 29.0, \"count\": 1, \"min\": 29, \"max\": 29}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:28 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=71191.77727515249 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:28 INFO 139703438038848] #quality_metric: host=algo-1, epoch=28, batch=0 train binary_classification_accuracy <score>=0.76\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:28 INFO 139703438038848] #quality_metric: host=algo-1, epoch=28, batch=0 train binary_classification_cross_entropy <loss>=0.5571744537353516\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:28 INFO 139703438038848] #quality_metric: host=algo-1, epoch=28, batch=0 train binary_f_1.000 <score>=0.8260869565217391\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:29.965] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 58, \"duration\": 1278, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:29 INFO 139703438038848] #quality_metric: host=algo-1, epoch=28, train binary_classification_accuracy <score>=0.7187637969094923\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:29 INFO 139703438038848] #quality_metric: host=algo-1, epoch=28, train binary_classification_cross_entropy <loss>=0.5844291282805386\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:29 INFO 139703438038848] #quality_metric: host=algo-1, epoch=28, train binary_f_1.000 <score>=0.7635047336179692\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199928.684569, \"EndTime\": 1640199929.9665515, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1281.0797691345215, \"count\": 1, \"min\": 1281.0797691345215, \"max\": 1281.0797691345215}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:29 INFO 139703438038848] #progress_metric: host=algo-1, completed 96.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199928.6854422, \"EndTime\": 1640199929.9668293, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2626730.0, \"count\": 1, \"min\": 2626730, \"max\": 2626730}, \"Total Batches Seen\": {\"sum\": 13138.0, \"count\": 1, \"min\": 13138, \"max\": 13138}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 30.0, \"count\": 1, \"min\": 30, \"max\": 30}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:29 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=70673.78814725403 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:29 INFO 139703438038848] #quality_metric: host=algo-1, epoch=29, batch=0 train binary_classification_accuracy <score>=0.76\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:29 INFO 139703438038848] #quality_metric: host=algo-1, epoch=29, batch=0 train binary_classification_cross_entropy <loss>=0.5558118438720703\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:29 INFO 139703438038848] #quality_metric: host=algo-1, epoch=29, batch=0 train binary_f_1.000 <score>=0.8260869565217391\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:31.266] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 60, \"duration\": 1296, \"num_examples\": 453, \"num_bytes\": 5796480}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:31 INFO 139703438038848] #quality_metric: host=algo-1, epoch=29, train binary_classification_accuracy <score>=0.7201876379690949\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:31 INFO 139703438038848] #quality_metric: host=algo-1, epoch=29, train binary_classification_cross_entropy <loss>=0.5827834277963533\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:31 INFO 139703438038848] #quality_metric: host=algo-1, epoch=29, train binary_f_1.000 <score>=0.7644418840189182\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:31 INFO 139703438038848] #quality_metric: host=algo-1, train binary_classification_accuracy <score>=0.7201876379690949\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:31 INFO 139703438038848] #quality_metric: host=algo-1, train binary_classification_cross_entropy <loss>=0.5827834277963533\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:31 INFO 139703438038848] #quality_metric: host=algo-1, train binary_f_1.000 <score>=0.7644418840189182\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199929.966636, \"EndTime\": 1640199931.267071, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 1299.90816116333, \"count\": 1, \"min\": 1299.90816116333, \"max\": 1299.90816116333}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:31 INFO 139703438038848] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199929.967132, \"EndTime\": 1640199931.267311, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2717300.0, \"count\": 1, \"min\": 2717300, \"max\": 2717300}, \"Total Batches Seen\": {\"sum\": 13591.0, \"count\": 1, \"min\": 13591, \"max\": 13591}, \"Max Records Seen Between Resets\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Max Batches Seen Between Resets\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}, \"Reset Count\": {\"sum\": 31.0, \"count\": 1, \"min\": 31, \"max\": 31}, \"Number of Records Since Last Reset\": {\"sum\": 90570.0, \"count\": 1, \"min\": 90570, \"max\": 90570}, \"Number of Batches Since Last Reset\": {\"sum\": 453.0, \"count\": 1, \"min\": 453, \"max\": 453}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:31 INFO 139703438038848] #throughput_metric: host=algo-1, train throughput=69653.31649382517 records/second\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:31 WARNING 139703438038848] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:31 INFO 139703438038848] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199931.2671416, \"EndTime\": 1640199931.2702599, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 2.6350021362304688, \"count\": 1, \"min\": 2.6350021362304688, \"max\": 2.6350021362304688}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:31 INFO 139703438038848] Saved checkpoint to \"/tmp/tmpggsah8bj/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:31.279] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 40625, \"num_examples\": 1, \"num_bytes\": 12800}\u001b[0m\n",
      "\u001b[34m[2021-12-22 19:05:31.392] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 113, \"num_examples\": 48, \"num_bytes\": 603392}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199931.2789257, \"EndTime\": 1640199931.392563, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"test_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9428.0, \"count\": 1, \"min\": 9428, \"max\": 9428}, \"Total Batches Seen\": {\"sum\": 48.0, \"count\": 1, \"min\": 48, \"max\": 48}, \"Max Records Seen Between Resets\": {\"sum\": 9428.0, \"count\": 1, \"min\": 9428, \"max\": 9428}, \"Max Batches Seen Between Resets\": {\"sum\": 48.0, \"count\": 1, \"min\": 48, \"max\": 48}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 9428.0, \"count\": 1, \"min\": 9428, \"max\": 9428}, \"Number of Batches Since Last Reset\": {\"sum\": 48.0, \"count\": 1, \"min\": 48, \"max\": 48}}}\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:31 INFO 139703438038848] #test_score (algo-1) : ('binary_classification_accuracy', 0.6934662706830717)\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:31 INFO 139703438038848] #test_score (algo-1) : ('binary_classification_cross_entropy', 0.6039596941190905)\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:31 INFO 139703438038848] #test_score (algo-1) : ('binary_f_1.000', 0.7624136797106215)\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:31 INFO 139703438038848] #quality_metric: host=algo-1, test binary_classification_accuracy <score>=0.6934662706830717\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:31 INFO 139703438038848] #quality_metric: host=algo-1, test binary_classification_cross_entropy <loss>=0.6039596941190905\u001b[0m\n",
      "\u001b[34m[12/22/2021 19:05:31 INFO 139703438038848] #quality_metric: host=algo-1, test binary_f_1.000 <score>=0.7624136797106215\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1640199931.2703269, \"EndTime\": 1640199931.3933032, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 22.398710250854492, \"count\": 1, \"min\": 22.398710250854492, \"max\": 22.398710250854492}, \"totaltime\": {\"sum\": 40775.3963470459, \"count\": 1, \"min\": 40775.3963470459, \"max\": 40775.3963470459}}}\u001b[0m\n",
      "\n",
      "2021-12-22 19:05:45 Uploading - Uploading generated training model\n",
      "2021-12-22 19:05:45 Completed - Training job completed\n",
      "Training seconds: 100\n",
      "Billable seconds: 100\n",
      "CPU times: user 635 ms, sys: 71.9 ms, total: 707 ms\n",
      "Wall time: 5min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "fm.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# **Train Job**\n",
       "| | |\n",
       "|---|---|\n",
       "| **Name** | factorization-machines-2021-12-22-19-00-47-575 |\n",
       "| **ARN**  | arn:aws:sagemaker:us-east-1:338408246139:training-job/factorization-machines-2021-12-22-19-00-47-575 |\n",
       "| **Creation Time** | 2021-12-22 19:00:47.805000+00:00 |\n",
       "| **Output** | s3://sagemaker-us-east-1-338408246139/builtin-notebooks/Recomendation-Machine/Explicit/output/factorization-machines-2021-12-22-19-00-47-575/output/model.tar.gz |\n",
       "| **Training Start Time** | 2021-12-22 19:04:05.210000+00:00 |\n",
       "| **Training End Time** | 2021-12-22 19:05:45.133000+00:00 |\n",
       "| **Training Time** | 100 seconds |\n",
       "| **Training Set Input** | s3://sagemaker-us-east-1-338408246139/builtin-notebooks/Recomendation-Machine/Explicit/train/ |\n",
       "\n",
       "## Hyperparameters\n",
       "| | |\n",
       "|---|---|\n",
       "| **epochs** | 30 |\n",
       "| **feature_dim** | 2623 |\n",
       "| **mini_batch_size** | 200 |\n",
       "| **num_factors** | 64 |\n",
       "| **predictor_type** | binary_classifier |\n",
       "\n",
       "## Metrics\n",
       "| | |\n",
       "|---|---|\n",
       "| **train:progress** | 100.0 |\n",
       "| **test:binary_f_beta** | 0.7624136805534363 |\n",
       "| **train:binary_classification_accuracy:batch** | 0.7599999904632568 |\n",
       "| **train:binary_f_beta:batch** | 0.8260869383811951 |\n",
       "| **train:binary_classification_cross_entropy:epoch** | 0.5827834010124207 |\n",
       "| **train:binary_f_beta** | 0.7644419074058533 |\n",
       "| **train:binary_classification_cross_entropy** | 0.5827834010124207 |\n",
       "| **train:binary_f_beta:epoch** | 0.7644419074058533 |\n",
       "| **train:binary_classification_accuracy:epoch** | 0.7201876640319824 |\n",
       "| **train:binary_classification_accuracy** | 0.7201876640319824 |\n",
       "| **test:binary_classification_cross_entropy** | 0.6039596796035767 |\n",
       "| **train:throughput** | 69653.3203125 |\n",
       "| **test:binary_classification_accuracy** | 0.6934662461280823 |\n",
       "| **train:binary_classification_cross_entropy:batch** | 0.5558118224143982 |\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, display_markdown\n",
    "\n",
    "job_desc = fm.latest_training_job.describe()\n",
    "\n",
    "job_name = job_desc[\"TrainingJobName\"]\n",
    "job_arn = job_desc[\"TrainingJobArn\"]\n",
    "creation_time = job_desc[\"CreationTime\"]\n",
    "train_start_time = job_desc[\"TrainingStartTime\"]\n",
    "train_end_time = job_desc[\"TrainingEndTime\"]\n",
    "job_output = job_desc[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "train_time = job_desc[\"TrainingTimeInSeconds\"]\n",
    "\n",
    "desc_md = f\"\"\"# **Train Job**\n",
    "| | |\n",
    "|---|---|\n",
    "| **Name** | {job_name} |\n",
    "| **ARN**  | {job_arn} |\n",
    "| **Creation Time** | {creation_time} |\n",
    "| **Output** | {job_output} |\n",
    "| **Training Start Time** | {train_start_time} |\n",
    "| **Training End Time** | {train_end_time} |\n",
    "| **Training Time** | {train_time} seconds |\n",
    "| **Training Set Input** | {s3_train} |\n",
    "\n",
    "## Hyperparameters\n",
    "| | |\n",
    "|---|---|\n",
    "\"\"\"\n",
    "for name, val in job_desc[\"HyperParameters\"].items():\n",
    "    desc_md += f\"| **{name}** | {val} |\\n\"\n",
    "\n",
    "desc_md += \"\"\"\n",
    "## Metrics\n",
    "| | |\n",
    "|---|---|\n",
    "\"\"\"\n",
    "for metric in job_desc[\"FinalMetricDataList\"]:\n",
    "    name, val = metric[\"MetricName\"], metric[\"Value\"]\n",
    "    desc_md += f\"| **{name}** | {val} |\\n\"\n",
    "\n",
    "display_markdown(desc_md, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Batch-Inference'></a>\n",
    "\n",
    "# Perform Batch Inference\n",
    "\n",
    "***\n",
    "\n",
    "We will use the trained model to perform a batch inference over a fixed set of observations. This can be useful when the trained model is being used as a Transformation step on a ETL pipeline, or when we need the results of the model to be precomputed (insted of getting live prediction requests on an endpoint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeDatasetToProtobuf2(X, bucket, prefix, key, d_type, Y=None):\n",
    "    buf = io.BytesIO()\n",
    "    if d_type==\"sparse\":\n",
    "        smac.write_spmatrix_to_sparse_tensor(buf, X, labels=Y)\n",
    "    else:\n",
    "        smac.write_numpy_to_dense_tensor(buf, X, labels=Y)\n",
    "        \n",
    "    buf.seek(0)\n",
    "    obj = '{}/{}'.format(prefix, key)\n",
    "    boto3.resource('s3').Bucket(bucket).Object(obj).upload_fileobj(buf)\n",
    "    return 's3://{}/{}'.format(bucket,obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch inference data path:  s3://sagemaker-us-east-1-338408246139/builtin-notebooks/Recomendation-Machine/Explicit/batch_inference/test.protobuf\n"
     ]
    }
   ],
   "source": [
    "#upload inference data to S3\n",
    "s3_batch_output = \"s3://{}/{}/batch_output/\".format(bucket, prefix)\n",
    "prefix_batch = \"{}/batch_inference\".format(prefix)\n",
    "\n",
    "s3_batch_input = writeDatasetToProtobuf2(X_test_OH, bucket, prefix_batch, test_key, \"sparse\")\n",
    "print (\"Batch inference data path: \",s3_batch_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_transformer = fm.transformer(\n",
    "    instance_count=1,\n",
    "    output_path=s3_batch_output,\n",
    "    instance_type=\"ml.c4.xlarge\",\n",
    "    max_payload=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Launching Batch Transform Job factorization-machines-2021-12-22-19-00-47-575-0d303ad3'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................................................................!\n",
      "CPU times: user 299 ms, sys: 31.2 ms, total: 330 ms\n",
      "Wall time: 6min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "transform_job_name = f\"{job_name}-{str(uuid.uuid4())[:8]}\"\n",
    "display(f\"Launching Batch Transform Job {transform_job_name}\")\n",
    "\n",
    "s3_batch_inference = \"s3://{}/{}/batch_inference/\".format(bucket, prefix)\n",
    "\n",
    "fm_transformer.transform(\n",
    "    data=s3_batch_inference,\n",
    "    split_type='RecordIO',\n",
    "    content_type=\"application/x-recordio-protobuf\",\n",
    "    job_name=transform_job_name,\n",
    "    wait=True,\n",
    "    logs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download predictions \n",
    "results_file_name = \"inference_batch_output\"\n",
    "results_prefix_name = '{}/batch_output/test.protobuf.out'.format(prefix)\n",
    "s3_client = boto3.client('s3')\n",
    "s3_client.download_file(bucket, results_prefix_name, results_file_name)\n",
    "with open(results_file_name) as f:\n",
    "    results = f.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>score</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.589505</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.577482</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.643375</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.648402</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.451894</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9423</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466676</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9424</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.546960</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9425</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.507472</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9426</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.435448</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.580828</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9428 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      predicted_label     score  rating  rating_bin\n",
       "0                 1.0  0.589505       4         1.0\n",
       "1                 1.0  0.577482       4         1.0\n",
       "2                 1.0  0.643375       4         1.0\n",
       "3                 1.0  0.648402       3         0.0\n",
       "4                 0.0  0.451894       2         0.0\n",
       "...               ...       ...     ...         ...\n",
       "9423              0.0  0.466676       4         1.0\n",
       "9424              1.0  0.546960       4         1.0\n",
       "9425              1.0  0.507472       1         0.0\n",
       "9426              0.0  0.435448       4         1.0\n",
       "9427              1.0  0.580828       2         0.0\n",
       "\n",
       "[9428 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.Series(results,name='predicted_label').apply(json.loads).apply(lambda x: x['predicted_label']),pd.Series(results,name='score').apply(json.loads).apply(lambda x: x['score']),ratings_test.rating,Y_test_OH],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy in dataset test is: 0.69\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos el accuracy del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('The accuracy in dataset test is: {}'.format(accuracy_score(Y_test_OH, pd.Series(results,name='predicted_label').apply(json.loads).apply(lambda x: x['predicted_label'])).round(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test_OH, pd.Series(results, name='predicted_label').apply(json.loads).apply(lambda x: x['predicted_label']))\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax, fmt='g')\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['low rating', 'high rating'])\n",
    "ax.yaxis.set_ticklabels(['low rating', 'high rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Real-Time-Inference'></a>\n",
    "\n",
    "# Perform Real-Time Inference\n",
    "\n",
    "***\n",
    "\n",
    "We now want to use the model to perform online inference. You can deploy the created model by using the `deploy` method in the `estimator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!CPU times: user 139 ms, sys: 13.9 ms, total: 153 ms\n",
      "Wall time: 4min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fm_predictor = fm.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.c4.xlarge\",\n",
    "    deserializer= JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Inferences'></a>\n",
    "## Inferences\n",
    "\n",
    "Factorization Machine is so often used with sparse data, performing inference requests with a CSV format (as is done in other algorithm examples) can be hugely inefficient. Instead of wasting space and time generating all those zeros, to fill the row with the correct dimensionality, JSON can be used more efficiently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Endpoints name: factorization-machines-2021-12-22-19-12-12-457'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "endpoint_name = fm_predictor.endpoint_name\n",
    "display(f\"Endpoints name: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_predictor = sagemaker.predictor.Predictor(endpoint_name, \n",
    "                                             sagemaker_session=sagemaker.Session(), \n",
    "                                             #serializer=FMSerializer(),\n",
    "                                             deserializer=JSONDeserializer()\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(data):\n",
    "    js = {'instances': []}\n",
    "    for row in data:\n",
    "        js['instances'].append({'features': row.tolist()})\n",
    "    return json.dumps(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'predicted_label': 1.0, 'score': 0.5895045399665833},\n",
      "                 {'predicted_label': 1.0, 'score': 0.5774816870689392},\n",
      "                 {'predicted_label': 1.0, 'score': 0.6433746814727783},\n",
      "                 {'predicted_label': 1.0, 'score': 0.6484015583992004},\n",
      "                 {'predicted_label': 0.0, 'score': 0.4518936276435852},\n",
      "                 {'predicted_label': 1.0, 'score': 0.5825338363647461},\n",
      "                 {'predicted_label': 1.0, 'score': 0.6893323659896851},\n",
      "                 {'predicted_label': 1.0, 'score': 0.7296139001846313},\n",
      "                 {'predicted_label': 1.0, 'score': 0.6663004159927368},\n",
      "                 {'predicted_label': 1.0, 'score': 0.6761026382446289},\n",
      "                 {'predicted_label': 1.0, 'score': 0.5885559320449829},\n",
      "                 {'predicted_label': 1.0, 'score': 0.8105983734130859},\n",
      "                 {'predicted_label': 1.0, 'score': 0.7238032221794128},\n",
      "                 {'predicted_label': 1.0, 'score': 0.5005598068237305},\n",
      "                 {'predicted_label': 0.0, 'score': 0.4851500988006592},\n",
      "                 {'predicted_label': 1.0, 'score': 0.5004498958587646},\n",
      "                 {'predicted_label': 1.0, 'score': 0.6151190996170044},\n",
      "                 {'predicted_label': 1.0, 'score': 0.6611725091934204},\n",
      "                 {'predicted_label': 1.0, 'score': 0.5037074089050293},\n",
      "                 {'predicted_label': 0.0, 'score': 0.49629291892051697}]}\n"
     ]
    }
   ],
   "source": [
    "cant_inferencias = 20\n",
    "X_test_json = serialize(X_test_OH[:cant_inferencias,:].toarray())\n",
    "result = fm_predictor.predict(X_test_json, initial_args={\"ContentType\": \"application/json\"})\n",
    "\n",
    "#print(X_test_json)\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of JSON format to pass the inferences has certain limitations, since the complete rows of o's and 1's are passed to it, it usually fails when a number of rows is exceeded (depending on the dimension of the dataset). One of the options is to make the inferences by parts and join the results. Another way that was found to solve this problem is to make the inferences, taking advantage of the fact that each row only contains information in the positions where they present 1 and not the zeros. The following JSON format is also accepted and much more optimal when it comes to inferring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(data, target):\n",
    "    js = {'instances': []}\n",
    "    shape = data.shape[1]\n",
    "    x_test = pd.DataFrame()\n",
    "    for row in data:\n",
    "        userId_index = row.tocoo().col[0]\n",
    "        movieId_index = row.tocoo().col[1]\n",
    "        x_test = x_test.append(pd.DataFrame({'userId':[enc.categories_[0][userId_index]], 'movieId':[enc.categories_[1][movieId_index-len(enc.categories_[0])]]}))\n",
    "        js['instances'].append({\"data\":{\"features\":{\"keys\": [int(userId_index), int(movieId_index)], \"shape\": [shape], \"values\": [1,1]}}})\n",
    "    salida = pd.concat([x_test.reset_index(drop=True), pd.DataFrame({'rating':target.astype(int)}).reset_index(drop=True)], axis=1)\n",
    "    return salida,json.dumps(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cant_inferencias = X_test_OH.shape[0]\n",
    "cant_inferencias = 100\n",
    "X_test,X_test_json = serialize(X_test_OH[:cant_inferencias,:], Y_test_OH[:cant_inferencias])\n",
    "result = fm_predictor.predict(X_test_json, initial_args={\"ContentType\": \"application/json\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.589505</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.577482</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.643375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.648402</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.451894</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.632684</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.657884</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.739731</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.675430</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.701271</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score  predicted_label\n",
       "0   0.589505              1.0\n",
       "1   0.577482              1.0\n",
       "2   0.643375              1.0\n",
       "3   0.648402              1.0\n",
       "4   0.451894              0.0\n",
       "..       ...              ...\n",
       "95  0.632684              1.0\n",
       "96  0.657884              1.0\n",
       "97  0.739731              1.0\n",
       "98  0.675430              1.0\n",
       "99  0.701271              1.0\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(result['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "n_predict = 3000\n",
    "n_iter = X_test_OH.shape[0]//n_predict \n",
    "\n",
    "print(n_predict)\n",
    "print(n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# **Inferences**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      userId  movieId  rating     score  predicted_label\n",
      "0          1       20       1  0.589505              1.0\n",
      "1          1       33       1  0.577482              1.0\n",
      "2          1       61       1  0.643375              1.0\n",
      "3          1      117       0  0.648402              1.0\n",
      "4          1      155       0  0.451894              0.0\n",
      "...      ...      ...     ...       ...              ...\n",
      "9423     943      232       1  0.466676              0.0\n",
      "9424     943      356       1  0.546960              1.0\n",
      "9425     943      570       0  0.507472              1.0\n",
      "9426     943      808       1  0.435448              0.0\n",
      "9427     943     1067       0  0.580828              1.0\n",
      "\n",
      "[9428 rows x 5 columns]\n",
      "CPU times: user 10.2 s, sys: 24.9 ms, total: 10.2 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "salida_test = pd.DataFrame()\n",
    "\n",
    "for i in range(n_iter+1):\n",
    "    if i==n_iter:\n",
    "        \n",
    "        X_test,X_test_json = serialize(X_test_OH[i*n_predict:,:], Y_test_OH[i*n_predict:])\n",
    "        result_i = fm_predictor.predict(X_test_json, initial_args={\"ContentType\": \"application/json\"})\n",
    "        salida_i = pd.DataFrame.from_dict(result_i['predictions'])\n",
    "        salida_i = pd.concat([X_test,salida_i],axis=1)\n",
    "        salida_test = salida_test.append(salida_i)\n",
    "    else:\n",
    "        \n",
    "        X_test,X_test_json = serialize(X_test_OH[i*n_predict:(i+1)*n_predict,:], Y_test_OH[i*n_predict:(i+1)*n_predict])\n",
    "        result_i = fm_predictor.predict(X_test_json, initial_args={\"ContentType\": \"application/json\"})\n",
    "        salida_i = pd.DataFrame.from_dict(result_i['predictions'])\n",
    "        salida_i = pd.concat([X_test,salida_i],axis=1)\n",
    "        salida_test = salida_test.append(salida_i)\n",
    "\n",
    "\n",
    "salida_test.reset_index(drop=True, inplace=True)\n",
    "desc_md = f\"\"\"# **Inferences**\"\"\"\n",
    "display_markdown(desc_md, raw=True)\n",
    "print(salida_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida_test.to_csv(\"prediccion_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Recommend'></a>\n",
    "## Recommend\n",
    "\n",
    "Finally, we are going to generate a Recommend function that will allow us to make the top X recommendations of the movies that I have not rated yet for each userID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(userId, data, enc, k=10):\n",
    "    \n",
    "    js = {'instances': []}\n",
    "    shape = len(enc.categories_[0])+len(enc.categories_[1])\n",
    "    recommend = pd.DataFrame()\n",
    "    \n",
    "    movie = data.movieId[data.userId==userId]\n",
    "    movie_not = set(data.movieId.unique())-set(movie)\n",
    "    userId_index = np.where(enc.categories_[0]==userId)[0][0]\n",
    "    for m in movie_not:\n",
    "        movie_index = np.where(enc.categories_[1]==m)[0][0]\n",
    "        js['instances'].append({\"data\":{\"features\":{\"keys\":[int(userId_index),int(movie_index)], \"shape\": [shape], \"values\": [1,1]}}})\n",
    "        \n",
    "    result = fm_predictor.predict(json.dumps(js), initial_args={\"ContentType\": \"application/json\"})\n",
    "    \n",
    "    recommend = pd.DataFrame.from_dict(result['predictions'])\n",
    "    recommend['userId'] = userId\n",
    "    recommend['movieId'] = movie_not\n",
    "    return recommend[['userId','movieId','score']].loc[recommend.predicted_label==1].sort_values(by='score',ascending=False).reset_index(drop=True).loc[:(k-1),:]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>993</td>\n",
       "      <td>0.836662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1007</td>\n",
       "      <td>0.831354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1041</td>\n",
       "      <td>0.827010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1426</td>\n",
       "      <td>0.825527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1070</td>\n",
       "      <td>0.819956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1261</td>\n",
       "      <td>0.819297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1422</td>\n",
       "      <td>0.818360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>955</td>\n",
       "      <td>0.815554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1370</td>\n",
       "      <td>0.813222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1117</td>\n",
       "      <td>0.809409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId     score\n",
       "0       1      993  0.836662\n",
       "1       1     1007  0.831354\n",
       "2       1     1041  0.827010\n",
       "3       1     1426  0.825527\n",
       "4       1     1070  0.819956\n",
       "5       1     1261  0.819297\n",
       "6       1     1422  0.818360\n",
       "7       1      955  0.815554\n",
       "8       1     1370  0.813222\n",
       "9       1     1117  0.809409"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend = recommend(1, ratings, enc)\n",
    "recommend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Clean'></a>\n",
    "### Clean up\n",
    "\n",
    "\n",
    "When we're done with the endpoint, we can just delete it and the backing instances will be released. Uncomment and run the following cell to delete the endpoint and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
